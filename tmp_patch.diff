*** Begin Patch
*** Update File: graphphysics/models/hierarchical_pooling.py
@@
-    def __init__(
+    def __init__(
         self,
         d_in: int,
         d_out: int,
         edge_dim: int,
         ratio: float = 0.25,
         k: int = 6,
         node_type_index: Optional[int] = None,
-        score_loss: Optional[_Loss] = None,
+        score_loss: Optional[_Loss] = None,
+        gradient_method: str = "finite_diff",
     ):
         super().__init__()
         self.ratio = ratio
         self.lin = nn.Linear(d_in, d_out)
         self.min_score = None
         self.nonlinearity = "softmax"
         self.edge_dim = edge_dim
         self.select = SelectTopK(d_in, self.ratio, self.min_score, self.nonlinearity)
         self.remesher = KNNGraph(k=k, force_undirected=True)
         self.node_type_index = node_type_index
-        self.score_loss = score_loss
+        self.score_loss = score_loss
+        self.gradient_method = gradient_method  # kept for compatibility
@@
-    def forward(
+    def forward(
         self,
         graph: Data,
         attn: Optional[torch.Tensor] = None,
     ) -> Data:
-
-        def _compute_score_values(self, graph: Data) -> torch.Tensor:
-            per_node = self.score_loss(
-            graph=graph,
-            node_type=self.node_type,
-            masks=self.score_masks,
-            selected_indexes=None,
-            gradient_method=self.score_gradient_method,
-            reduce=False,
-            return_masked=False,
-            )
-            return per_node
-
-        if attn is None and self.score_loss is not None:
-            score_values = self._compute_score_values(graph)
-            if self.score_select is None:
-                raise ValueError(
-                    "Score loss provided but score selector is not initialized."
-                )
-            score_input = score_values.unsqueeze(-1)
-            select_out = self.score_select(score_input, graph)
-        else:
-            scores = graph.x if attn is None else attn
-            select_out = self.select(scores, graph)
+        # Build batch vector for SelectTopK
+        batch = getattr(graph, "batch", None)
+        if batch is None:
+            batch = graph.x.new_zeros(graph.x.size(0), dtype=torch.long)
+
+        # Default scoring: use node features or provided attention
+        scores = graph.x if attn is None else attn
+        select_out = self.select(scores, batch)
         perm = select_out.node_index
*** End Patch
